#!/bin/bash -x

#SBATCH --output=L400m-igresnext-lit-%j.log
#SBATCH --nodes=4
#SBATCH --ntasks-per-node=4
#SBATCH --cpus-per-task=8
#SBATCH --time=47:59:00
#SBATCH --mem=256GB
#SBATCH --gres=gpu:4
#SBATCH --job-name=l400m-igresnext-lit
#SBATCH --mail-type=BEGIN,END
#SBATCH --mail-user=bf996@nyu.edu

module purge;

#debug flags
echo $SLURM_JOB_NAME

#env vars
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK;
export MASTER_PORT=$(shuf -i 10000-65500 -n 1);
export MASTER_ADDR="$(hostname -s).hpc.nyu.edu";

#run command
srun --cpu_bind=v --accel-bind=v \
    /bin/bash src/script/run-singularity.bash \
    /bin/bash -c \
    'export PYTHONPATH="$PYTHONPATH:$PWD/src"; python src/training/main.py --report-to wandb --dataset-type webdataset --train-data "/vast/work/public/ml-datasets/laion400m/{01500..41500}.tar" --train-num-samples 180000000 --save-frequency 1 --warmup 2000 --batch-size=128 --epochs=32 --workers=8 --model=timm-igresnext32x48 --norm_gradient_clip=5e4 --resume "/scratch/bf996/open_clip/logs/laion400m-180mtrain-igresnext-lit-ep1/checkpoints/epoch_1.pt" --pretrained-image --lock-image --local-loss --gather-with-grad'
